{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece8df0f-0c0c-46be-9692-5176ba8fbb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.features import rasterize\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, f1_score, \n",
    "                            roc_curve, auc, confusion_matrix, \n",
    "                            classification_report, roc_auc_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4730e22e-35cb-4ac6-bcf6-e6a2b96acbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA RTX A5000\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# 设置设备（GPU或CPU）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c661d0c5-e613-4a6d-a5aa-ab210aebd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 数据准备函数（与之前相同）\n",
    "def prepare_data(env_rasters, landslide_shp, non_landslide_shp, sample_size=15000):\n",
    "    \"\"\"\n",
    "    准备训练数据集\n",
    "    :param env_rasters: 环境因子栅格路径列表\n",
    "    :param landslide_shp: 滑坡点Shapefile路径\n",
    "    :param non_landslide_shp: 非滑坡点Shapefile路径\n",
    "    :param sample_size: 每类采样点数\n",
    "    :return: 特征数组, 标签数组, 栅格元数据, 特征名称\n",
    "    \"\"\"\n",
    "    # 读取滑坡点数据\n",
    "    landslide_gdf = gpd.read_file(landslide_shp)\n",
    "    non_landslide_gdf = gpd.read_file(non_landslide_shp)\n",
    "    \n",
    "    # 随机采样\n",
    "    if len(landslide_gdf) > sample_size:\n",
    "        landslide_gdf = landslide_gdf.sample(sample_size, random_state=42)\n",
    "    if len(non_landslide_gdf) > sample_size:\n",
    "        non_landslide_gdf = non_landslide_gdf.sample(sample_size, random_state=42)\n",
    "    \n",
    "    # 合并点数据并添加标签\n",
    "    landslide_gdf['label'] = 1\n",
    "    non_landslide_gdf['label'] = 0\n",
    "    all_points = pd.concat([landslide_gdf, non_landslide_gdf])\n",
    "    \n",
    "    # 初始化特征数组\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # 读取第一个栅格获取元数据\n",
    "    with rasterio.open(env_rasters[0]) as src:\n",
    "        meta = src.meta\n",
    "        transform = src.transform\n",
    "        height, width = src.shape\n",
    "    \n",
    "    # 提取每个点的特征值\n",
    "    print(\"提取点特征值...\")\n",
    "    for idx, point in tqdm(all_points.iterrows(), total=len(all_points)):\n",
    "        geom = point.geometry\n",
    "        if geom is None:\n",
    "            continue\n",
    "            \n",
    "        # 获取点坐标\n",
    "        x, y = geom.x, geom.y\n",
    "        \n",
    "        # 转换为栅格坐标\n",
    "        col, row = ~transform * (x, y)\n",
    "        col, row = int(col), int(row)\n",
    "        \n",
    "        # 检查坐标是否在范围内\n",
    "        if 0 <= row < height and 0 <= col < width:\n",
    "            point_features = []\n",
    "            valid = True\n",
    "            \n",
    "            # 读取所有栅格在该点的值\n",
    "            for raster_path in env_rasters:\n",
    "                with rasterio.open(raster_path) as src:\n",
    "                    value = src.read(1, window=((row, row+1), (col, col+1)))\n",
    "                    if np.isnan(value).any() or value[0][0] == src.nodata:\n",
    "                        valid = False\n",
    "                        break\n",
    "                    point_features.append(value[0][0])\n",
    "            \n",
    "            if valid:\n",
    "                features.append(point_features)\n",
    "                labels.append(point['label'])\n",
    "    \n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # 获取特征名称\n",
    "    feature_names = [os.path.basename(r).split('.')[0] for r in env_rasters]\n",
    "    \n",
    "    print(f\"提取完成: {features.shape[0]}个样本, {features.shape[1]}个特征\")\n",
    "    return features, labels, meta, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6b56a7-aad1-423a-ac04-21b3e62b4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LSTM模型定义（替代CNN）\n",
    "class LandslideLSTM(nn.Module):\n",
    "    def __init__(self, input_size=13, hidden_size=64, num_layers=2, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        LSTM模型用于滑坡敏感性评估\n",
    "        \n",
    "        参数:\n",
    "        input_size: 每个时间步的特征数量（即环境因子数量）\n",
    "        hidden_size: LSTM隐藏层大小\n",
    "        num_layers: LSTM层数\n",
    "        dropout_rate: Dropout概率\n",
    "        \"\"\"\n",
    "        super(LandslideLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM层\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,  # 输入格式为(batch, seq_len, features)\n",
    "            dropout=dropout_rate if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # Dropout层\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # 激活函数\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 添加序列维度: (batch, features) -> (batch, 1, features)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # 初始化隐藏状态\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # LSTM前向传播\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # 取最后一个时间步的输出\n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        # 全连接层\n",
    "        out = self.fc(self.dropout(out))\n",
    "        \n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# 3. 训练函数（与之前相同，但模型改为LSTM）\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=100, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_auc': []}\n",
    "    \n",
    "    # 将模型移至设备\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            # 将数据移至设备\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                # 将数据移至设备\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                probs = outputs.squeeze()\n",
    "                preds = (probs > 0.5).float()\n",
    "                \n",
    "                all_probs.extend(probs.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # 计算指标\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = accuracy_score(all_labels, all_preds)\n",
    "        val_auc = roc_auc_score(all_labels, all_probs)\n",
    "        \n",
    "        # 记录历史\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_auc'].append(val_auc)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), 'best_landslide_model_lstm.pth')\n",
    "        \n",
    "        # 早停检查OC\n",
    "        if epoch - best_epoch > patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Time: {epoch_time:.1f}s | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | \"\n",
    "              f\"Val Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# 4. 评估函数（与之前相同）\n",
    "def evaluate_model(model, test_loader):\n",
    "    # 将模型移至设备\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # 将数据移至设备\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = outputs.squeeze()\n",
    "            preds = (probs > 0.5).float()\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # 计算指标\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "    \n",
    "    # 计算ROC曲线\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "    \n",
    "    # 绘制ROC曲线\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve_lstm.pdf',format='pdf',bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    \n",
    "    # 绘制混淆矩阵\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Non-Landslide', 'Landslide'],\n",
    "                yticklabels=['Non-Landslide', 'Landslide'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix_lstm.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return all_probs, all_preds, all_labels\n",
    "\n",
    "# 5. 区域预测函数（与之前相同）\n",
    "def predict_region(model, env_rasters, meta, scaler, output_path='landslide_susceptibility_lstm.tif'):\n",
    "    \"\"\"\n",
    "    对整个研究区进行滑坡敏感性预测\n",
    "    :param model: 训练好的模型\n",
    "    :param env_rasters: 环境因子栅格路径列表\n",
    "    :param meta: 栅格元数据\n",
    "    :param scaler: 标准化器\n",
    "    :param output_path: 输出路径\n",
    "    \"\"\"\n",
    "    # 更新元数据\n",
    "    meta.update(count=1, dtype='float32', nodata=-9999)\n",
    "    \n",
    "    # 获取栅格尺寸\n",
    "    with rasterio.open(env_rasters[0]) as src:\n",
    "        height, width = src.shape\n",
    "        transform = src.transform\n",
    "    \n",
    "    # 创建输出栅格\n",
    "    with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "        # 分块处理以避免内存不足\n",
    "        block_size = 256\n",
    "        num_blocks_x = (width + block_size - 1) // block_size\n",
    "        num_blocks_y = (height + block_size - 1) // block_size\n",
    "        \n",
    "        print(f\"开始区域预测 ({height}x{width}), 分块: {num_blocks_x}x{num_blocks_y}\")\n",
    "        \n",
    "        # 创建进度条\n",
    "        pbar = tqdm(total=num_blocks_x * num_blocks_y, desc=\"区域预测\")\n",
    "        \n",
    "        # 将模型移至设备\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        for y_block in range(num_blocks_y):\n",
    "            for x_block in range(num_blocks_x):\n",
    "                # 计算当前块的位置\n",
    "                x_offset = x_block * block_size\n",
    "                y_offset = y_block * block_size\n",
    "                win_width = min(block_size, width - x_offset)\n",
    "                win_height = min(block_size, height - y_offset)\n",
    "                \n",
    "                # 读取所有栅格数据\n",
    "                block_data = []\n",
    "                for raster_path in env_rasters:\n",
    "                    with rasterio.open(raster_path) as src:\n",
    "                        data = src.read(1, window=((y_offset, y_offset+win_height), \n",
    "                                                  (x_offset, x_offset+win_width)))\n",
    "                        block_data.append(data)\n",
    "                \n",
    "                # 堆叠为特征数组\n",
    "                block_stack = np.stack(block_data, axis=-1)\n",
    "                original_shape = block_stack.shape\n",
    "                \n",
    "                # 转换为2D数组 (height*width, features)\n",
    "                block_2d = block_stack.reshape(-1, original_shape[-1])\n",
    "                \n",
    "                # 处理无效值\n",
    "                valid_mask = ~np.isnan(block_2d).any(axis=1)\n",
    "                valid_data = block_2d[valid_mask]\n",
    "                \n",
    "                # 如果没有有效数据，跳过\n",
    "                if valid_data.size == 0:\n",
    "                    result = np.full(valid_mask.shape, meta['nodata'], dtype=np.float32)\n",
    "                    result = result.reshape(original_shape[:-1])\n",
    "                    dst.write(result, 1, window=((y_offset, y_offset+win_height), \n",
    "                                                (x_offset, x_offset+win_width)))\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # 标准化\n",
    "                valid_data = scaler.transform(valid_data)\n",
    "                \n",
    "                # 转换为Tensor并移至设备\n",
    "                valid_tensor = torch.tensor(valid_data, dtype=torch.float32).to(device)\n",
    "                \n",
    "                # 预测\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(valid_tensor)\n",
    "                    probs = outputs.squeeze().cpu().numpy()\n",
    "                \n",
    "                # 创建结果数组\n",
    "                result = np.full(valid_mask.shape, meta['nodata'], dtype=np.float32)\n",
    "                result[valid_mask] = probs\n",
    "                result = result.reshape(original_shape[:-1])\n",
    "                \n",
    "                # 写入结果\n",
    "                dst.write(result, 1, window=((y_offset, y_offset+win_height), \n",
    "                                            (x_offset, x_offset+win_width)))\n",
    "                \n",
    "                pbar.update(1)\n",
    "        \n",
    "        pbar.close()\n",
    "    \n",
    "    print(f\"区域预测完成，结果保存至: {output_path}\")\n",
    "\n",
    "# 6. 可视化函数（与之前相同）\n",
    "def visualize_results(output_path):\n",
    "    \"\"\"可视化滑坡敏感性图\"\"\"\n",
    "    with rasterio.open(output_path) as src:\n",
    "        data = src.read(1)\n",
    "        \n",
    "        # 设置颜色映射\n",
    "        colors = ['#f7fbff', '#deebf7', '#c6dbef', '#9ecae1', '#6baed6', \n",
    "                 '#4292c6', '#2171b5', '#08519c', '#08306b']\n",
    "        cmap = mcolors.LinearSegmentedColormap.from_list(\"susceptibility\", colors)\n",
    "        \n",
    "        # 创建图像\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        show(data, cmap=cmap, title='Landslide Susceptibility', vmin=0, vmax=1)\n",
    "        plt.colorbar(label='Susceptibility Probability')\n",
    "        plt.savefig('susceptibility_map_lstm.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdc5d39-4951-4093-94f2-06dbe6e70eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准备训练数据...\n",
      "提取点特征值...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28980/28980 [11:35<00:00, 41.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取完成: 28980个样本, 13个特征\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ENV_RASTERS = [\n",
    "    'Slope.tif',\n",
    "    'Aspect.tif',\n",
    "    'PlanCurvature.tif',\n",
    "    'ProfCurvature.tif',\n",
    "    'Distance_to_fault.tif',\n",
    "    'Distance_to_river.tif',\n",
    "    'Distance_to_road.tif',\n",
    "    'NDVI.tif',\n",
    "    'TWI.tif',\n",
    "    'elevation.tif',\n",
    "    'Landuse.tif',\n",
    "    'LItgology.tif',\n",
    "    'Sen`s_slope_of_rain.tif'\n",
    "    ]\n",
    "LANDSLIDE_SHP = '滑坡.shp'\n",
    "NON_LANDSLIDE_SHP = '非滑坡.shp'\n",
    "\n",
    "# 1. 准备数据\n",
    "print(\"准备训练数据...\")\n",
    "features, labels, meta, feature_names = prepare_data(\n",
    "    ENV_RASTERS, LANDSLIDE_SHP, NON_LANDSLIDE_SHP, sample_size=15000\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ceaa900-d5b2-49e3-9c7f-4f1288f3912b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练LSTM模型...\n",
      "Epoch 1/200 | Time: 0.2s | Train Loss: 0.5860 | Val Loss: 0.4614 | Val Acc: 0.7787 | Val AUC: 0.8579\n",
      "Epoch 2/200 | Time: 0.2s | Train Loss: 0.4449 | Val Loss: 0.4153 | Val Acc: 0.7920 | Val AUC: 0.8823\n",
      "Epoch 3/200 | Time: 0.2s | Train Loss: 0.4138 | Val Loss: 0.3916 | Val Acc: 0.8135 | Val AUC: 0.8952\n",
      "Epoch 4/200 | Time: 0.2s | Train Loss: 0.3920 | Val Loss: 0.3760 | Val Acc: 0.8255 | Val AUC: 0.9025\n",
      "Epoch 5/200 | Time: 0.2s | Train Loss: 0.3809 | Val Loss: 0.3661 | Val Acc: 0.8337 | Val AUC: 0.9074\n",
      "Epoch 6/200 | Time: 0.2s | Train Loss: 0.3722 | Val Loss: 0.3572 | Val Acc: 0.8415 | Val AUC: 0.9118\n",
      "Epoch 7/200 | Time: 0.3s | Train Loss: 0.3683 | Val Loss: 0.3514 | Val Acc: 0.8430 | Val AUC: 0.9153\n",
      "Epoch 8/200 | Time: 0.2s | Train Loss: 0.3604 | Val Loss: 0.3458 | Val Acc: 0.8467 | Val AUC: 0.9179\n",
      "Epoch 9/200 | Time: 0.2s | Train Loss: 0.3549 | Val Loss: 0.3450 | Val Acc: 0.8521 | Val AUC: 0.9204\n",
      "Epoch 10/200 | Time: 0.2s | Train Loss: 0.3518 | Val Loss: 0.3384 | Val Acc: 0.8477 | Val AUC: 0.9219\n",
      "Epoch 11/200 | Time: 0.2s | Train Loss: 0.3492 | Val Loss: 0.3345 | Val Acc: 0.8556 | Val AUC: 0.9239\n",
      "Epoch 12/200 | Time: 0.2s | Train Loss: 0.3456 | Val Loss: 0.3319 | Val Acc: 0.8536 | Val AUC: 0.9256\n",
      "Epoch 13/200 | Time: 0.2s | Train Loss: 0.3455 | Val Loss: 0.3297 | Val Acc: 0.8539 | Val AUC: 0.9265\n",
      "Epoch 14/200 | Time: 0.2s | Train Loss: 0.3386 | Val Loss: 0.3260 | Val Acc: 0.8578 | Val AUC: 0.9283\n",
      "Epoch 15/200 | Time: 0.2s | Train Loss: 0.3378 | Val Loss: 0.3243 | Val Acc: 0.8620 | Val AUC: 0.9297\n",
      "Epoch 16/200 | Time: 0.2s | Train Loss: 0.3334 | Val Loss: 0.3222 | Val Acc: 0.8590 | Val AUC: 0.9302\n",
      "Epoch 17/200 | Time: 0.2s | Train Loss: 0.3343 | Val Loss: 0.3189 | Val Acc: 0.8608 | Val AUC: 0.9321\n",
      "Epoch 18/200 | Time: 0.2s | Train Loss: 0.3306 | Val Loss: 0.3174 | Val Acc: 0.8635 | Val AUC: 0.9325\n",
      "Epoch 19/200 | Time: 0.2s | Train Loss: 0.3274 | Val Loss: 0.3135 | Val Acc: 0.8647 | Val AUC: 0.9341\n",
      "Epoch 20/200 | Time: 0.2s | Train Loss: 0.3257 | Val Loss: 0.3122 | Val Acc: 0.8642 | Val AUC: 0.9342\n",
      "Epoch 21/200 | Time: 0.2s | Train Loss: 0.3243 | Val Loss: 0.3096 | Val Acc: 0.8669 | Val AUC: 0.9355\n",
      "Epoch 22/200 | Time: 0.2s | Train Loss: 0.3221 | Val Loss: 0.3087 | Val Acc: 0.8662 | Val AUC: 0.9356\n",
      "Epoch 23/200 | Time: 0.2s | Train Loss: 0.3203 | Val Loss: 0.3065 | Val Acc: 0.8706 | Val AUC: 0.9372\n",
      "Epoch 24/200 | Time: 0.2s | Train Loss: 0.3193 | Val Loss: 0.3048 | Val Acc: 0.8691 | Val AUC: 0.9376\n",
      "Epoch 25/200 | Time: 0.2s | Train Loss: 0.3180 | Val Loss: 0.3048 | Val Acc: 0.8667 | Val AUC: 0.9369\n",
      "Epoch 26/200 | Time: 0.2s | Train Loss: 0.3133 | Val Loss: 0.3020 | Val Acc: 0.8691 | Val AUC: 0.9381\n",
      "Epoch 27/200 | Time: 0.2s | Train Loss: 0.3147 | Val Loss: 0.3007 | Val Acc: 0.8753 | Val AUC: 0.9394\n",
      "Epoch 28/200 | Time: 0.2s | Train Loss: 0.3130 | Val Loss: 0.2999 | Val Acc: 0.8724 | Val AUC: 0.9390\n",
      "Epoch 29/200 | Time: 0.2s | Train Loss: 0.3116 | Val Loss: 0.2972 | Val Acc: 0.8726 | Val AUC: 0.9406\n",
      "Epoch 30/200 | Time: 0.2s | Train Loss: 0.3084 | Val Loss: 0.2962 | Val Acc: 0.8741 | Val AUC: 0.9408\n",
      "Epoch 31/200 | Time: 0.2s | Train Loss: 0.3077 | Val Loss: 0.2952 | Val Acc: 0.8758 | Val AUC: 0.9415\n",
      "Epoch 32/200 | Time: 0.2s | Train Loss: 0.3066 | Val Loss: 0.2936 | Val Acc: 0.8738 | Val AUC: 0.9418\n",
      "Epoch 33/200 | Time: 0.2s | Train Loss: 0.3052 | Val Loss: 0.2923 | Val Acc: 0.8763 | Val AUC: 0.9427\n",
      "Epoch 34/200 | Time: 0.2s | Train Loss: 0.3034 | Val Loss: 0.2920 | Val Acc: 0.8765 | Val AUC: 0.9429\n",
      "Epoch 35/200 | Time: 0.2s | Train Loss: 0.3015 | Val Loss: 0.2895 | Val Acc: 0.8797 | Val AUC: 0.9435\n",
      "Epoch 36/200 | Time: 0.2s | Train Loss: 0.2998 | Val Loss: 0.2879 | Val Acc: 0.8810 | Val AUC: 0.9443\n",
      "Epoch 37/200 | Time: 0.3s | Train Loss: 0.3008 | Val Loss: 0.2875 | Val Acc: 0.8805 | Val AUC: 0.9441\n",
      "Epoch 38/200 | Time: 0.2s | Train Loss: 0.2984 | Val Loss: 0.2862 | Val Acc: 0.8805 | Val AUC: 0.9449\n",
      "Epoch 39/200 | Time: 0.2s | Train Loss: 0.2981 | Val Loss: 0.2855 | Val Acc: 0.8805 | Val AUC: 0.9452\n",
      "Epoch 40/200 | Time: 0.2s | Train Loss: 0.2961 | Val Loss: 0.2848 | Val Acc: 0.8795 | Val AUC: 0.9451\n",
      "Epoch 41/200 | Time: 0.2s | Train Loss: 0.2951 | Val Loss: 0.2842 | Val Acc: 0.8797 | Val AUC: 0.9453\n",
      "Epoch 42/200 | Time: 0.2s | Train Loss: 0.2919 | Val Loss: 0.2826 | Val Acc: 0.8849 | Val AUC: 0.9461\n",
      "Epoch 43/200 | Time: 0.2s | Train Loss: 0.2926 | Val Loss: 0.2813 | Val Acc: 0.8834 | Val AUC: 0.9466\n",
      "Epoch 44/200 | Time: 0.2s | Train Loss: 0.2934 | Val Loss: 0.2790 | Val Acc: 0.8825 | Val AUC: 0.9473\n",
      "Epoch 45/200 | Time: 0.2s | Train Loss: 0.2891 | Val Loss: 0.2787 | Val Acc: 0.8854 | Val AUC: 0.9480\n",
      "Epoch 46/200 | Time: 0.2s | Train Loss: 0.2892 | Val Loss: 0.2785 | Val Acc: 0.8839 | Val AUC: 0.9472\n",
      "Epoch 47/200 | Time: 0.2s | Train Loss: 0.2866 | Val Loss: 0.2764 | Val Acc: 0.8874 | Val AUC: 0.9482\n",
      "Epoch 48/200 | Time: 0.2s | Train Loss: 0.2858 | Val Loss: 0.2754 | Val Acc: 0.8874 | Val AUC: 0.9485\n",
      "Epoch 49/200 | Time: 0.2s | Train Loss: 0.2850 | Val Loss: 0.2741 | Val Acc: 0.8881 | Val AUC: 0.9489\n",
      "Epoch 50/200 | Time: 0.2s | Train Loss: 0.2862 | Val Loss: 0.2734 | Val Acc: 0.8866 | Val AUC: 0.9494\n",
      "Epoch 51/200 | Time: 0.2s | Train Loss: 0.2835 | Val Loss: 0.2716 | Val Acc: 0.8859 | Val AUC: 0.9498\n",
      "Epoch 52/200 | Time: 0.2s | Train Loss: 0.2815 | Val Loss: 0.2717 | Val Acc: 0.8862 | Val AUC: 0.9496\n",
      "Epoch 53/200 | Time: 0.2s | Train Loss: 0.2810 | Val Loss: 0.2697 | Val Acc: 0.8901 | Val AUC: 0.9505\n",
      "Epoch 54/200 | Time: 0.2s | Train Loss: 0.2757 | Val Loss: 0.2695 | Val Acc: 0.8889 | Val AUC: 0.9504\n",
      "Epoch 55/200 | Time: 0.2s | Train Loss: 0.2794 | Val Loss: 0.2684 | Val Acc: 0.8891 | Val AUC: 0.9510\n",
      "Epoch 56/200 | Time: 0.2s | Train Loss: 0.2786 | Val Loss: 0.2674 | Val Acc: 0.8896 | Val AUC: 0.9514\n",
      "Epoch 57/200 | Time: 0.2s | Train Loss: 0.2756 | Val Loss: 0.2664 | Val Acc: 0.8898 | Val AUC: 0.9515\n",
      "Epoch 58/200 | Time: 0.2s | Train Loss: 0.2721 | Val Loss: 0.2659 | Val Acc: 0.8911 | Val AUC: 0.9517\n",
      "Epoch 59/200 | Time: 0.2s | Train Loss: 0.2748 | Val Loss: 0.2637 | Val Acc: 0.8935 | Val AUC: 0.9525\n",
      "Epoch 60/200 | Time: 0.2s | Train Loss: 0.2739 | Val Loss: 0.2642 | Val Acc: 0.8894 | Val AUC: 0.9521\n",
      "Epoch 61/200 | Time: 0.2s | Train Loss: 0.2703 | Val Loss: 0.2632 | Val Acc: 0.8913 | Val AUC: 0.9526\n",
      "Epoch 62/200 | Time: 0.2s | Train Loss: 0.2698 | Val Loss: 0.2623 | Val Acc: 0.8945 | Val AUC: 0.9529\n",
      "Epoch 63/200 | Time: 0.2s | Train Loss: 0.2682 | Val Loss: 0.2611 | Val Acc: 0.8894 | Val AUC: 0.9531\n",
      "Epoch 64/200 | Time: 0.2s | Train Loss: 0.2680 | Val Loss: 0.2596 | Val Acc: 0.8940 | Val AUC: 0.9537\n",
      "Epoch 65/200 | Time: 0.3s | Train Loss: 0.2695 | Val Loss: 0.2586 | Val Acc: 0.8965 | Val AUC: 0.9540\n",
      "Epoch 66/200 | Time: 0.2s | Train Loss: 0.2668 | Val Loss: 0.2603 | Val Acc: 0.8918 | Val AUC: 0.9535\n",
      "Epoch 67/200 | Time: 0.2s | Train Loss: 0.2655 | Val Loss: 0.2588 | Val Acc: 0.8923 | Val AUC: 0.9540\n",
      "Epoch 68/200 | Time: 0.2s | Train Loss: 0.2658 | Val Loss: 0.2577 | Val Acc: 0.8950 | Val AUC: 0.9543\n",
      "Epoch 69/200 | Time: 0.2s | Train Loss: 0.2648 | Val Loss: 0.2568 | Val Acc: 0.8926 | Val AUC: 0.9545\n",
      "Epoch 70/200 | Time: 0.2s | Train Loss: 0.2634 | Val Loss: 0.2571 | Val Acc: 0.8960 | Val AUC: 0.9544\n",
      "Epoch 71/200 | Time: 0.2s | Train Loss: 0.2655 | Val Loss: 0.2563 | Val Acc: 0.8963 | Val AUC: 0.9545\n",
      "Epoch 72/200 | Time: 0.2s | Train Loss: 0.2610 | Val Loss: 0.2555 | Val Acc: 0.8980 | Val AUC: 0.9550\n",
      "Epoch 73/200 | Time: 0.2s | Train Loss: 0.2604 | Val Loss: 0.2548 | Val Acc: 0.9004 | Val AUC: 0.9553\n",
      "Epoch 74/200 | Time: 0.2s | Train Loss: 0.2618 | Val Loss: 0.2522 | Val Acc: 0.9019 | Val AUC: 0.9558\n",
      "Epoch 75/200 | Time: 0.2s | Train Loss: 0.2615 | Val Loss: 0.2534 | Val Acc: 0.8985 | Val AUC: 0.9553\n",
      "Epoch 76/200 | Time: 0.2s | Train Loss: 0.2594 | Val Loss: 0.2518 | Val Acc: 0.9009 | Val AUC: 0.9560\n",
      "Epoch 77/200 | Time: 0.2s | Train Loss: 0.2560 | Val Loss: 0.2520 | Val Acc: 0.8995 | Val AUC: 0.9560\n",
      "Epoch 78/200 | Time: 0.2s | Train Loss: 0.2572 | Val Loss: 0.2511 | Val Acc: 0.8997 | Val AUC: 0.9562\n",
      "Epoch 79/200 | Time: 0.2s | Train Loss: 0.2578 | Val Loss: 0.2505 | Val Acc: 0.9019 | Val AUC: 0.9563\n",
      "Epoch 80/200 | Time: 0.2s | Train Loss: 0.2538 | Val Loss: 0.2493 | Val Acc: 0.9036 | Val AUC: 0.9567\n",
      "Epoch 81/200 | Time: 0.2s | Train Loss: 0.2555 | Val Loss: 0.2486 | Val Acc: 0.9032 | Val AUC: 0.9569\n",
      "Epoch 82/200 | Time: 0.2s | Train Loss: 0.2557 | Val Loss: 0.2491 | Val Acc: 0.9000 | Val AUC: 0.9568\n",
      "Epoch 83/200 | Time: 0.2s | Train Loss: 0.2553 | Val Loss: 0.2486 | Val Acc: 0.9022 | Val AUC: 0.9572\n",
      "Epoch 84/200 | Time: 0.2s | Train Loss: 0.2536 | Val Loss: 0.2484 | Val Acc: 0.9044 | Val AUC: 0.9569\n",
      "Epoch 85/200 | Time: 0.2s | Train Loss: 0.2490 | Val Loss: 0.2468 | Val Acc: 0.9024 | Val AUC: 0.9576\n",
      "Epoch 86/200 | Time: 0.2s | Train Loss: 0.2516 | Val Loss: 0.2450 | Val Acc: 0.9049 | Val AUC: 0.9578\n",
      "Epoch 87/200 | Time: 0.2s | Train Loss: 0.2465 | Val Loss: 0.2454 | Val Acc: 0.9051 | Val AUC: 0.9580\n",
      "Epoch 88/200 | Time: 0.2s | Train Loss: 0.2512 | Val Loss: 0.2453 | Val Acc: 0.9049 | Val AUC: 0.9577\n",
      "Epoch 89/200 | Time: 0.2s | Train Loss: 0.2489 | Val Loss: 0.2431 | Val Acc: 0.9059 | Val AUC: 0.9584\n",
      "Epoch 90/200 | Time: 0.2s | Train Loss: 0.2477 | Val Loss: 0.2423 | Val Acc: 0.9078 | Val AUC: 0.9586\n",
      "Epoch 91/200 | Time: 0.2s | Train Loss: 0.2497 | Val Loss: 0.2452 | Val Acc: 0.9059 | Val AUC: 0.9576\n",
      "Epoch 92/200 | Time: 0.2s | Train Loss: 0.2448 | Val Loss: 0.2420 | Val Acc: 0.9064 | Val AUC: 0.9586\n",
      "Epoch 93/200 | Time: 0.3s | Train Loss: 0.2455 | Val Loss: 0.2415 | Val Acc: 0.9076 | Val AUC: 0.9587\n",
      "Epoch 94/200 | Time: 0.2s | Train Loss: 0.2437 | Val Loss: 0.2410 | Val Acc: 0.9081 | Val AUC: 0.9590\n",
      "Epoch 95/200 | Time: 0.2s | Train Loss: 0.2433 | Val Loss: 0.2420 | Val Acc: 0.9051 | Val AUC: 0.9590\n",
      "Epoch 96/200 | Time: 0.2s | Train Loss: 0.2422 | Val Loss: 0.2409 | Val Acc: 0.9076 | Val AUC: 0.9591\n",
      "Epoch 97/200 | Time: 0.2s | Train Loss: 0.2412 | Val Loss: 0.2402 | Val Acc: 0.9081 | Val AUC: 0.9591\n",
      "Epoch 98/200 | Time: 0.2s | Train Loss: 0.2426 | Val Loss: 0.2406 | Val Acc: 0.9073 | Val AUC: 0.9592\n",
      "Epoch 99/200 | Time: 0.2s | Train Loss: 0.2424 | Val Loss: 0.2410 | Val Acc: 0.9078 | Val AUC: 0.9592\n",
      "Epoch 100/200 | Time: 0.2s | Train Loss: 0.2406 | Val Loss: 0.2383 | Val Acc: 0.9086 | Val AUC: 0.9600\n",
      "Epoch 101/200 | Time: 0.2s | Train Loss: 0.2408 | Val Loss: 0.2378 | Val Acc: 0.9096 | Val AUC: 0.9600\n",
      "Epoch 102/200 | Time: 0.2s | Train Loss: 0.2388 | Val Loss: 0.2383 | Val Acc: 0.9098 | Val AUC: 0.9602\n",
      "Epoch 103/200 | Time: 0.2s | Train Loss: 0.2364 | Val Loss: 0.2367 | Val Acc: 0.9110 | Val AUC: 0.9606\n",
      "Epoch 104/200 | Time: 0.2s | Train Loss: 0.2399 | Val Loss: 0.2364 | Val Acc: 0.9096 | Val AUC: 0.9605\n",
      "Epoch 105/200 | Time: 0.2s | Train Loss: 0.2352 | Val Loss: 0.2377 | Val Acc: 0.9081 | Val AUC: 0.9604\n",
      "Epoch 106/200 | Time: 0.2s | Train Loss: 0.2358 | Val Loss: 0.2354 | Val Acc: 0.9105 | Val AUC: 0.9608\n",
      "Epoch 107/200 | Time: 0.2s | Train Loss: 0.2371 | Val Loss: 0.2367 | Val Acc: 0.9091 | Val AUC: 0.9606\n",
      "Epoch 108/200 | Time: 0.2s | Train Loss: 0.2374 | Val Loss: 0.2359 | Val Acc: 0.9101 | Val AUC: 0.9606\n",
      "Epoch 109/200 | Time: 0.2s | Train Loss: 0.2351 | Val Loss: 0.2341 | Val Acc: 0.9101 | Val AUC: 0.9612\n",
      "Epoch 110/200 | Time: 0.2s | Train Loss: 0.2316 | Val Loss: 0.2336 | Val Acc: 0.9118 | Val AUC: 0.9612\n",
      "Epoch 111/200 | Time: 0.2s | Train Loss: 0.2338 | Val Loss: 0.2333 | Val Acc: 0.9120 | Val AUC: 0.9611\n",
      "Epoch 112/200 | Time: 0.2s | Train Loss: 0.2326 | Val Loss: 0.2332 | Val Acc: 0.9118 | Val AUC: 0.9613\n",
      "Epoch 113/200 | Time: 0.2s | Train Loss: 0.2344 | Val Loss: 0.2322 | Val Acc: 0.9128 | Val AUC: 0.9616\n",
      "Epoch 114/200 | Time: 0.2s | Train Loss: 0.2286 | Val Loss: 0.2335 | Val Acc: 0.9103 | Val AUC: 0.9614\n",
      "Epoch 115/200 | Time: 0.2s | Train Loss: 0.2303 | Val Loss: 0.2303 | Val Acc: 0.9133 | Val AUC: 0.9621\n",
      "Epoch 116/200 | Time: 0.2s | Train Loss: 0.2287 | Val Loss: 0.2304 | Val Acc: 0.9133 | Val AUC: 0.9620\n",
      "Epoch 117/200 | Time: 0.2s | Train Loss: 0.2281 | Val Loss: 0.2306 | Val Acc: 0.9115 | Val AUC: 0.9622\n",
      "Epoch 118/200 | Time: 0.2s | Train Loss: 0.2273 | Val Loss: 0.2295 | Val Acc: 0.9133 | Val AUC: 0.9623\n",
      "Epoch 119/200 | Time: 0.2s | Train Loss: 0.2245 | Val Loss: 0.2286 | Val Acc: 0.9140 | Val AUC: 0.9627\n",
      "Epoch 120/200 | Time: 0.2s | Train Loss: 0.2258 | Val Loss: 0.2295 | Val Acc: 0.9123 | Val AUC: 0.9625\n",
      "Epoch 121/200 | Time: 0.2s | Train Loss: 0.2265 | Val Loss: 0.2286 | Val Acc: 0.9140 | Val AUC: 0.9625\n",
      "Epoch 122/200 | Time: 0.3s | Train Loss: 0.2258 | Val Loss: 0.2276 | Val Acc: 0.9142 | Val AUC: 0.9630\n",
      "Epoch 123/200 | Time: 0.2s | Train Loss: 0.2241 | Val Loss: 0.2281 | Val Acc: 0.9135 | Val AUC: 0.9631\n",
      "Epoch 124/200 | Time: 0.2s | Train Loss: 0.2239 | Val Loss: 0.2272 | Val Acc: 0.9133 | Val AUC: 0.9632\n",
      "Epoch 125/200 | Time: 0.2s | Train Loss: 0.2247 | Val Loss: 0.2268 | Val Acc: 0.9120 | Val AUC: 0.9631\n",
      "Epoch 126/200 | Time: 0.2s | Train Loss: 0.2239 | Val Loss: 0.2278 | Val Acc: 0.9120 | Val AUC: 0.9636\n",
      "Epoch 127/200 | Time: 0.2s | Train Loss: 0.2223 | Val Loss: 0.2280 | Val Acc: 0.9130 | Val AUC: 0.9633\n",
      "Epoch 128/200 | Time: 0.2s | Train Loss: 0.2224 | Val Loss: 0.2263 | Val Acc: 0.9135 | Val AUC: 0.9635\n",
      "Epoch 129/200 | Time: 0.2s | Train Loss: 0.2260 | Val Loss: 0.2249 | Val Acc: 0.9160 | Val AUC: 0.9637\n",
      "Epoch 130/200 | Time: 0.2s | Train Loss: 0.2229 | Val Loss: 0.2257 | Val Acc: 0.9140 | Val AUC: 0.9637\n",
      "Epoch 131/200 | Time: 0.2s | Train Loss: 0.2227 | Val Loss: 0.2244 | Val Acc: 0.9150 | Val AUC: 0.9639\n",
      "Epoch 132/200 | Time: 0.2s | Train Loss: 0.2201 | Val Loss: 0.2259 | Val Acc: 0.9138 | Val AUC: 0.9641\n",
      "Epoch 133/200 | Time: 0.2s | Train Loss: 0.2193 | Val Loss: 0.2238 | Val Acc: 0.9155 | Val AUC: 0.9642\n",
      "Epoch 134/200 | Time: 0.2s | Train Loss: 0.2212 | Val Loss: 0.2258 | Val Acc: 0.9150 | Val AUC: 0.9640\n",
      "Epoch 135/200 | Time: 0.2s | Train Loss: 0.2181 | Val Loss: 0.2223 | Val Acc: 0.9170 | Val AUC: 0.9646\n",
      "Epoch 136/200 | Time: 0.2s | Train Loss: 0.2189 | Val Loss: 0.2239 | Val Acc: 0.9152 | Val AUC: 0.9644\n",
      "Epoch 137/200 | Time: 0.2s | Train Loss: 0.2184 | Val Loss: 0.2233 | Val Acc: 0.9170 | Val AUC: 0.9647\n",
      "Epoch 138/200 | Time: 0.2s | Train Loss: 0.2183 | Val Loss: 0.2226 | Val Acc: 0.9179 | Val AUC: 0.9647\n",
      "Epoch 139/200 | Time: 0.2s | Train Loss: 0.2155 | Val Loss: 0.2219 | Val Acc: 0.9174 | Val AUC: 0.9644\n",
      "Epoch 140/200 | Time: 0.2s | Train Loss: 0.2210 | Val Loss: 0.2196 | Val Acc: 0.9184 | Val AUC: 0.9655\n",
      "Epoch 141/200 | Time: 0.2s | Train Loss: 0.2158 | Val Loss: 0.2198 | Val Acc: 0.9182 | Val AUC: 0.9655\n",
      "Epoch 142/200 | Time: 0.2s | Train Loss: 0.2148 | Val Loss: 0.2205 | Val Acc: 0.9150 | Val AUC: 0.9654\n",
      "Epoch 143/200 | Time: 0.2s | Train Loss: 0.2156 | Val Loss: 0.2203 | Val Acc: 0.9174 | Val AUC: 0.9654\n",
      "Epoch 144/200 | Time: 0.2s | Train Loss: 0.2164 | Val Loss: 0.2193 | Val Acc: 0.9174 | Val AUC: 0.9654\n",
      "Epoch 145/200 | Time: 0.2s | Train Loss: 0.2126 | Val Loss: 0.2221 | Val Acc: 0.9167 | Val AUC: 0.9650\n",
      "Epoch 146/200 | Time: 0.2s | Train Loss: 0.2117 | Val Loss: 0.2212 | Val Acc: 0.9155 | Val AUC: 0.9652\n",
      "Epoch 147/200 | Time: 0.2s | Train Loss: 0.2129 | Val Loss: 0.2191 | Val Acc: 0.9170 | Val AUC: 0.9659\n",
      "Epoch 148/200 | Time: 0.2s | Train Loss: 0.2126 | Val Loss: 0.2197 | Val Acc: 0.9170 | Val AUC: 0.9658\n",
      "Epoch 149/200 | Time: 0.2s | Train Loss: 0.2104 | Val Loss: 0.2182 | Val Acc: 0.9170 | Val AUC: 0.9660\n",
      "Epoch 150/200 | Time: 0.3s | Train Loss: 0.2111 | Val Loss: 0.2200 | Val Acc: 0.9157 | Val AUC: 0.9660\n",
      "Epoch 151/200 | Time: 0.2s | Train Loss: 0.2083 | Val Loss: 0.2182 | Val Acc: 0.9179 | Val AUC: 0.9660\n",
      "Epoch 152/200 | Time: 0.2s | Train Loss: 0.2116 | Val Loss: 0.2182 | Val Acc: 0.9172 | Val AUC: 0.9660\n",
      "Epoch 153/200 | Time: 0.2s | Train Loss: 0.2092 | Val Loss: 0.2183 | Val Acc: 0.9187 | Val AUC: 0.9660\n",
      "Epoch 154/200 | Time: 0.2s | Train Loss: 0.2124 | Val Loss: 0.2184 | Val Acc: 0.9177 | Val AUC: 0.9660\n",
      "Epoch 155/200 | Time: 0.2s | Train Loss: 0.2078 | Val Loss: 0.2175 | Val Acc: 0.9189 | Val AUC: 0.9661\n",
      "Epoch 156/200 | Time: 0.2s | Train Loss: 0.2103 | Val Loss: 0.2184 | Val Acc: 0.9179 | Val AUC: 0.9660\n",
      "Epoch 157/200 | Time: 0.2s | Train Loss: 0.2103 | Val Loss: 0.2190 | Val Acc: 0.9172 | Val AUC: 0.9661\n",
      "Epoch 158/200 | Time: 0.2s | Train Loss: 0.2092 | Val Loss: 0.2166 | Val Acc: 0.9192 | Val AUC: 0.9664\n",
      "Epoch 159/200 | Time: 0.2s | Train Loss: 0.2048 | Val Loss: 0.2162 | Val Acc: 0.9187 | Val AUC: 0.9666\n",
      "Epoch 160/200 | Time: 0.2s | Train Loss: 0.2077 | Val Loss: 0.2149 | Val Acc: 0.9207 | Val AUC: 0.9668\n",
      "Epoch 161/200 | Time: 0.2s | Train Loss: 0.2074 | Val Loss: 0.2149 | Val Acc: 0.9202 | Val AUC: 0.9668\n",
      "Epoch 162/200 | Time: 0.2s | Train Loss: 0.2065 | Val Loss: 0.2141 | Val Acc: 0.9211 | Val AUC: 0.9672\n",
      "Epoch 163/200 | Time: 0.2s | Train Loss: 0.2063 | Val Loss: 0.2151 | Val Acc: 0.9184 | Val AUC: 0.9671\n",
      "Epoch 164/200 | Time: 0.2s | Train Loss: 0.2062 | Val Loss: 0.2155 | Val Acc: 0.9204 | Val AUC: 0.9669\n",
      "Epoch 165/200 | Time: 0.2s | Train Loss: 0.2082 | Val Loss: 0.2133 | Val Acc: 0.9207 | Val AUC: 0.9672\n",
      "Epoch 166/200 | Time: 0.2s | Train Loss: 0.1979 | Val Loss: 0.2141 | Val Acc: 0.9209 | Val AUC: 0.9673\n",
      "Epoch 167/200 | Time: 0.2s | Train Loss: 0.2086 | Val Loss: 0.2133 | Val Acc: 0.9216 | Val AUC: 0.9671\n",
      "Epoch 168/200 | Time: 0.2s | Train Loss: 0.2045 | Val Loss: 0.2124 | Val Acc: 0.9209 | Val AUC: 0.9676\n",
      "Epoch 169/200 | Time: 0.2s | Train Loss: 0.2049 | Val Loss: 0.2109 | Val Acc: 0.9219 | Val AUC: 0.9679\n",
      "Epoch 170/200 | Time: 0.2s | Train Loss: 0.2054 | Val Loss: 0.2117 | Val Acc: 0.9204 | Val AUC: 0.9681\n",
      "Epoch 171/200 | Time: 0.2s | Train Loss: 0.2044 | Val Loss: 0.2132 | Val Acc: 0.9167 | Val AUC: 0.9680\n",
      "Epoch 172/200 | Time: 0.2s | Train Loss: 0.2056 | Val Loss: 0.2091 | Val Acc: 0.9221 | Val AUC: 0.9687\n",
      "Epoch 173/200 | Time: 0.2s | Train Loss: 0.2042 | Val Loss: 0.2089 | Val Acc: 0.9209 | Val AUC: 0.9688\n",
      "Epoch 174/200 | Time: 0.2s | Train Loss: 0.2053 | Val Loss: 0.2099 | Val Acc: 0.9194 | Val AUC: 0.9685\n",
      "Epoch 175/200 | Time: 0.2s | Train Loss: 0.1999 | Val Loss: 0.2102 | Val Acc: 0.9202 | Val AUC: 0.9684\n",
      "Epoch 176/200 | Time: 0.2s | Train Loss: 0.2002 | Val Loss: 0.2104 | Val Acc: 0.9197 | Val AUC: 0.9687\n",
      "Epoch 177/200 | Time: 0.2s | Train Loss: 0.1991 | Val Loss: 0.2092 | Val Acc: 0.9231 | Val AUC: 0.9685\n",
      "Epoch 178/200 | Time: 0.3s | Train Loss: 0.1992 | Val Loss: 0.2111 | Val Acc: 0.9189 | Val AUC: 0.9682\n",
      "Epoch 179/200 | Time: 0.2s | Train Loss: 0.1970 | Val Loss: 0.2093 | Val Acc: 0.9216 | Val AUC: 0.9685\n",
      "Epoch 180/200 | Time: 0.2s | Train Loss: 0.1968 | Val Loss: 0.2096 | Val Acc: 0.9207 | Val AUC: 0.9685\n",
      "Epoch 181/200 | Time: 0.2s | Train Loss: 0.1978 | Val Loss: 0.2092 | Val Acc: 0.9226 | Val AUC: 0.9686\n",
      "Epoch 182/200 | Time: 0.2s | Train Loss: 0.1991 | Val Loss: 0.2100 | Val Acc: 0.9219 | Val AUC: 0.9684\n",
      "Epoch 183/200 | Time: 0.2s | Train Loss: 0.2003 | Val Loss: 0.2097 | Val Acc: 0.9214 | Val AUC: 0.9687\n",
      "Epoch 184/200 | Time: 0.2s | Train Loss: 0.1961 | Val Loss: 0.2076 | Val Acc: 0.9226 | Val AUC: 0.9689\n",
      "Epoch 185/200 | Time: 0.2s | Train Loss: 0.1981 | Val Loss: 0.2090 | Val Acc: 0.9219 | Val AUC: 0.9690\n",
      "Epoch 186/200 | Time: 0.2s | Train Loss: 0.1959 | Val Loss: 0.2091 | Val Acc: 0.9209 | Val AUC: 0.9690\n",
      "Epoch 187/200 | Time: 0.2s | Train Loss: 0.1935 | Val Loss: 0.2073 | Val Acc: 0.9234 | Val AUC: 0.9688\n",
      "Epoch 188/200 | Time: 0.2s | Train Loss: 0.2018 | Val Loss: 0.2092 | Val Acc: 0.9202 | Val AUC: 0.9688\n",
      "Epoch 189/200 | Time: 0.2s | Train Loss: 0.1936 | Val Loss: 0.2072 | Val Acc: 0.9214 | Val AUC: 0.9694\n",
      "Epoch 190/200 | Time: 0.2s | Train Loss: 0.1934 | Val Loss: 0.2071 | Val Acc: 0.9211 | Val AUC: 0.9695\n",
      "Epoch 191/200 | Time: 0.2s | Train Loss: 0.1984 | Val Loss: 0.2056 | Val Acc: 0.9229 | Val AUC: 0.9699\n",
      "Epoch 192/200 | Time: 0.2s | Train Loss: 0.1971 | Val Loss: 0.2068 | Val Acc: 0.9216 | Val AUC: 0.9694\n",
      "Epoch 193/200 | Time: 0.2s | Train Loss: 0.1979 | Val Loss: 0.2055 | Val Acc: 0.9219 | Val AUC: 0.9697\n",
      "Epoch 194/200 | Time: 0.2s | Train Loss: 0.1957 | Val Loss: 0.2057 | Val Acc: 0.9221 | Val AUC: 0.9699\n",
      "Epoch 195/200 | Time: 0.2s | Train Loss: 0.1937 | Val Loss: 0.2075 | Val Acc: 0.9226 | Val AUC: 0.9698\n",
      "Epoch 196/200 | Time: 0.2s | Train Loss: 0.1925 | Val Loss: 0.2049 | Val Acc: 0.9229 | Val AUC: 0.9699\n",
      "Epoch 197/200 | Time: 0.2s | Train Loss: 0.1928 | Val Loss: 0.2055 | Val Acc: 0.9234 | Val AUC: 0.9699\n",
      "Epoch 198/200 | Time: 0.2s | Train Loss: 0.1933 | Val Loss: 0.2042 | Val Acc: 0.9221 | Val AUC: 0.9700\n",
      "Epoch 199/200 | Time: 0.2s | Train Loss: 0.1902 | Val Loss: 0.2071 | Val Acc: 0.9209 | Val AUC: 0.9700\n",
      "Epoch 200/200 | Time: 0.2s | Train Loss: 0.1881 | Val Loss: 0.2063 | Val Acc: 0.9231 | Val AUC: 0.9700\n"
     ]
    }
   ],
   "source": [
    "# 2. 数据预处理\n",
    "# 划分训练/测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.3, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 转换为Tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# 划分验证集\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(\n",
    "    train_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "batch_size = 256 if device.type == \"cuda\" else 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 3. 初始化LSTM模型\n",
    "input_size = len(feature_names)\n",
    "model = LandslideLSTM(\n",
    "    input_size=input_size,\n",
    "    hidden_size=128,  # 增加隐藏层大小\n",
    "    num_layers=2,     # 双层LSTM\n",
    "    dropout_rate=0.4\n",
    ")\n",
    "\n",
    "# 添加多GPU支持（如果可用）\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"使用 {torch.cuda.device_count()} 个GPU进行训练\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# 4. 训练模型\n",
    "print(\"开始训练LSTM模型...\")\n",
    "history = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, epochs=200, patience=15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d21a93-b6ad-4bfd-a75b-2e9edaf13bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "评估模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_20492\\2068580098.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_landslide_model_lstm.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9218\n",
      "F1 Score: 0.9240\n",
      "AUC: 0.9716\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.89      0.92      4347\n",
      "         1.0       0.90      0.95      0.92      4347\n",
      "\n",
      "    accuracy                           0.92      8694\n",
      "   macro avg       0.92      0.92      0.92      8694\n",
      "weighted avg       0.92      0.92      0.92      8694\n",
      "\n",
      "\n",
      "对整个研究区进行预测...\n",
      "开始区域预测 (1937x1521), 分块: 6x8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "区域预测: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:07<00:00,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "区域预测完成，结果保存至: landslide_susceptibility_lstm.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. 评估模型\n",
    "print(\"\\n评估模型...\")\n",
    "# 加载最佳模型（注意设备映射）\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model.module.load_state_dict(torch.load('best_landslide_model_lstm.pth', map_location=device))\n",
    "else:\n",
    "    model.load_state_dict(torch.load('best_landslide_model_lstm.pth', map_location=device))\n",
    "\n",
    "probs, preds, test_labels = evaluate_model(model, test_loader)\n",
    "\n",
    "# 保存测试结果\n",
    "test_results = pd.DataFrame({\n",
    "    'Probability': probs,\n",
    "    'Prediction': preds,\n",
    "    'Actual_Label': test_labels\n",
    "})\n",
    "test_results['Susceptibility'] = test_results['Probability'].apply(\n",
    "    lambda p: 'High' if p > 0.5 else 'Low'\n",
    ")\n",
    "test_results.to_csv('landslide_test_results_lstm.csv', index=False)\n",
    "\n",
    "# 6. 对整个研究区进行预测\n",
    "print(\"\\n对整个研究区进行预测...\")\n",
    "# 确保使用单GPU进行区域预测\n",
    "if torch.cuda.device_count() > 1:\n",
    "    predict_model = model.module\n",
    "else:\n",
    "    predict_model = model\n",
    "\n",
    "predict_region(predict_model, ENV_RASTERS, meta, scaler, \n",
    "              output_path='landslide_susceptibility_lstm.tif')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cea2b6-3afd-40c8-a71e-e96945848344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 可视化结果\n",
    "print(\"\\n可视化结果...\")\n",
    "# visualize_results('landslide_susceptibility_lstm.tif')\n",
    "\n",
    "# 8. 绘制训练历史\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy', color='green')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history['val_auc'], label='Validation AUC', color='purple')\n",
    "plt.title('Validation AUC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('training_history_lstm.png')\n",
    "plt.close()\n",
    "\n",
    "# 9. 清理GPU内存\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"已清理GPU内存\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
